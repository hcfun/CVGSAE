import torch.nn as nn
import torch
import dgl
from GAE import VGAE
import numpy as np

class Model(nn.Module):
    def __init__(self, args):
        super(Model, self).__init__()
        self.args = args
        # self.dim = args.dim

        self.rel_feat = nn.Parameter(torch.Tensor(self.args.num_rel, self.args.rel_dim))
        nn.init.xavier_uniform_(self.rel_feat, gain=nn.init.calculate_gain('relu'))

        # self.rel_feat = nn.Parameter(torch.Tensor(args.num_rel_bases, self.args.rel_dim))
        # nn.init.xavier_uniform_(self.rel_feat, gain=nn.init.calculate_gain('relu'))

        self.ent_feat = nn.Parameter(torch.Tensor(self.args.num_ent, self.args.ent_dim))
        nn.init.xavier_uniform_(self.ent_feat, gain=nn.init.calculate_gain('relu'))

        self.rel_head_feat = nn.Parameter(torch.Tensor(self.args.rel_dim, self.args.ent_dim))
        self.rel_tail_feat = nn.Parameter(torch.Tensor(self.args.rel_dim, self.args.ent_dim))
        nn.init.xavier_uniform_(self.rel_head_feat, gain=nn.init.calculate_gain('relu'))
        nn.init.xavier_uniform_(self.rel_tail_feat, gain=nn.init.calculate_gain('relu'))

        self.metarel_head_feat = nn.Parameter(torch.Tensor(self.args.rel_dim, self.args.rel_dim))
        self.metarel_tail_feat = nn.Parameter(torch.Tensor(self.args.rel_dim, self.args.rel_dim))
        nn.init.xavier_uniform_(self.metarel_head_feat, gain=nn.init.calculate_gain('relu'))
        nn.init.xavier_uniform_(self.metarel_tail_feat, gain=nn.init.calculate_gain('relu'))

        self.pattern_rel_ent = nn.Parameter(torch.Tensor(12, self.args.rel_dim))
        nn.init.xavier_uniform_(self.pattern_rel_ent, gain=nn.init.calculate_gain('relu'))

        self.vgae = VGAE(self.args)
        self.time_encoder = TimeEncode(self.args.time_dim)



    # relation feature representation
    def init_pattern_g(self, pattern_g):
        with pattern_g.local_scope():
            # embedding of edge_type in pattern_g
            num_edge = pattern_g.num_edges()
            etypes = pattern_g.edata['rel']

            metarel_head_emb = torch.matmul(self.pattern_rel_ent, self.metarel_head_feat)
            metarel_tail_emb = torch.matmul(self.pattern_rel_ent, self.metarel_tail_feat)

            pattern_g.edata['edge_h'] = torch.zeros(num_edge, self.args.rel_dim).to(self.args.gpu)

            non_inv_idx = (pattern_g.edata['inv'] == 0)  # the front half edges
            inv_idx = (pattern_g.edata['inv'] == 1)  # the latter half edges
            pattern_g.edata['edge_h'][inv_idx] = metarel_head_emb[etypes[inv_idx]]
            pattern_g.edata['edge_h'][non_inv_idx] = metarel_tail_emb[etypes[non_inv_idx]]

            message_func = dgl.function.copy_e('edge_h', 'msg')
            reduce_func = dgl.function.mean('msg', 'h')
            pattern_g.update_all(message_func, reduce_func)
            pattern_g.edata.pop('edge_h')

            # for observed ent
            obs_idx = (pattern_g.ndata['ori_idx'] != -1)
            pattern_g.ndata['h'][obs_idx] = self.rel_feat[pattern_g.ndata['ori_idx'][obs_idx]]

            rel_feat = pattern_g.ndata['h']

        return rel_feat

    # entity feature representation
    def init_g(self, g, rel_feat):
        with g.local_scope():######bi_directional batched graph (contain original and inverse relations)
            num_edge = g.num_edges()
            etypes = g.edata['b_rel']

            rel_head_emb = torch.matmul(rel_feat, self.rel_head_feat)  # inverse rel embs
            rel_tail_emb = torch.matmul(rel_feat, self.rel_tail_feat)  # original rel embs

            # etimes = g.edata['time']
            # time_head_emb = torch.matmul(time_emb, self.time_head_feat)  # inverse time embs
            # time_tail_emb = torch.matmul(time_emb, self.time_tail_feat)  # original time embs

            g.edata['edge_h'] = torch.zeros(num_edge, self.args.ent_dim).to(self.args.gpu)

            non_inv_idx = (g.edata['inv'] == 0)  # the front half edges
            inv_idx = (g.edata['inv'] == 1)  # the latter half edges
            g.edata['edge_h'][inv_idx] = rel_head_emb[etypes[inv_idx]]
            g.edata['edge_h'][non_inv_idx] = rel_tail_emb[etypes[non_inv_idx]]

            message_func = dgl.function.copy_e('edge_h', 'msg')
            reduce_func = dgl.function.mean('msg', 'h')
            g.update_all(message_func, reduce_func)
            g.edata.pop('edge_h')

            # for observed ent
            obs_idx = (g.ndata['ori_idx'] != -1)
            g.ndata['h'][obs_idx] = self.ent_feat[g.ndata['ori_idx'][obs_idx]]

            ent_feat = g.ndata['h']


        return ent_feat

    def forward(self, g, pattern_g):
        time_emb = self.time_encoder(torch.arange(self.args.num_time).to(self.args.gpu))
        init_rel_feat = self.init_pattern_g(pattern_g)  # rel_embs contain initialized seen rels and unseen rel embs generated by relation position
        init_ent_feat = self.init_g(g, init_rel_feat)

        ent_emb, ent_emb_out, rel_emb, rel_emb_out, time_emb, time_emb_out, metarel_emb, metarel_emb_out = self.vgae(g, pattern_g, ent_feat=init_ent_feat, rel_feat=init_rel_feat, time_emb = time_emb, metarel_emb = self.pattern_rel_ent)



        return ent_emb, ent_emb_out, rel_emb, rel_emb_out, time_emb, time_emb_out, metarel_emb, metarel_emb_out

    def vgae_loss_f(self,e, out_e, r, out_r):
        return self.vgae.vgae_loss_f(e, out_e, r, out_r)


class TimeEncode(torch.nn.Module):
    def __init__(self, emb_dim):
        super(TimeEncode, self).__init__()

        time_dim = emb_dim
        self.basis_freq = torch.nn.Parameter((torch.from_numpy(1 / 10 ** np.linspace(0, 9, time_dim))).float())
        self.phase = torch.nn.Parameter(torch.zeros(time_dim).float())


    def forward(self, times):

        times = times.view(-1, 1)

        map_ts = times * self.basis_freq.view(1, -1)
        map_ts += self.phase.view(1, -1)

        harmonic = torch.cos(map_ts)

        return harmonic